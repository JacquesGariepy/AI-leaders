# AI-leaders

# Liste des Experts en Deep Learning, LLMs, et Prompt Engineering

## Experts en Deep Learning

1. **Andrew Ng** : Co-fondateur de Coursera et pionnier dans le domaine du deep learning, il a également dirigé des projets d'IA chez Google Brain.
   - LinkedIn : [Andrew Ng](https://www.linkedin.com/in/andrewyng/)
   - GitHub : [andrewng](https://github.com/andrewng)

2. **Andrej Karpathy** : Ancien ingénieur en chef chez Tesla, spécialiste en vision par ordinateur et apprentissage profond, il a également travaillé sur des modèles de langage chez OpenAI.
   - LinkedIn : [Andrej Karpathy](https://www.linkedin.com/in/karpathy/)
   - GitHub : [karpathy](https://github.com/karpathy)

3. **Jeff Dean** : Responsable de Google AI et co-fondateur de Google Brain, il est l'un des leaders dans le développement de l'intelligence artificielle et du machine learning à grande échelle.
   - LinkedIn : [Jeff Dean](https://www.linkedin.com/in/jeffdean/)
   - GitHub : N/A

4. **Ilya Sutskever** : Co-fondateur et scientifique en chef chez OpenAI, il a contribué de manière significative aux modèles de deep learning, notamment GPT.
   - LinkedIn : [Ilya Sutskever](https://www.linkedin.com/in/ilya-sutskever/)
   - GitHub : [ilyasu](https://github.com/ilyasu)

5. **Yann LeCun** : Pionnier des réseaux de neurones convolutifs et directeur de l'IA chez Meta, il est l'un des fondateurs du deep learning moderne.
   - LinkedIn : [Yann LeCun](https://www.linkedin.com/in/yann-lecun-82540a1/)
   - GitHub : [ylecun](https://github.com/ylecun)

6. **Geoffrey Hinton** : Connu comme le "parrain du deep learning", il a contribué au développement des réseaux de neurones profonds et a reçu le Prix Turing pour ses travaux révolutionnaires.
   - LinkedIn : N/A
   - GitHub : [geoffhinton](https://github.com/geoffhinton)

7. **Yoshua Bengio** : Lauréat du Prix Turing, il a apporté des contributions majeures aux architectures de réseaux de neurones et est un leader de la recherche en IA au Canada.
   - LinkedIn : [Yoshua Bengio](https://www.linkedin.com/in/yoshua-bengio-6964b25a/)
   - GitHub : [yoshuaBengio](https://github.com/yoshuaBengio)

8. **Fei-Fei Li** : Experte en vision par ordinateur et professeure à Stanford, elle a dirigé le projet ImageNet, qui a été crucial pour les avancées en reconnaissance d'images.
   - LinkedIn : [Fei-Fei Li](https://www.linkedin.com/in/feifei-li-6610a029/)
   - GitHub : N/A

9. **Ian Goodfellow** : Inventeur des réseaux antagonistes génératifs (GANs), il a révolutionné la génération d'images et d'autres données synthétiques en IA.
   - LinkedIn : [Ian Goodfellow](https://www.linkedin.com/in/ian-goodfellow-859b661b/)
   - GitHub : [goodfeli](https://github.com/goodfeli)

10. **Soumith Chintala** : Co-créateur de PyTorch, il a facilité le développement de nombreux modèles de deep learning de pointe grâce à cette bibliothèque open-source.
    - LinkedIn : [Soumith Chintala](https://www.linkedin.com/in/soumith/)
    - GitHub : [soumith](https://github.com/soumith)

11. **Sebastian Raschka** : Auteur du livre "Python Machine Learning" et expert en deep learning, il partage des ressources pédagogiques de haute qualité.
    - LinkedIn : [Sebastian Raschka](https://www.linkedin.com/in/sebastianraschka/)
    - GitHub : [rasbt](https://github.com/rasbt)

12. **François Chollet** : Créateur de Keras, une bibliothèque open-source de deep learning, et auteur du livre "Deep Learning with Python".
    - LinkedIn : [François Chollet](https://www.linkedin.com/in/fchollet/)
    - GitHub : [fchollet](https://github.com/fchollet)

13. **Hugo Larochelle** : Chercheur en IA chez Google Brain, il est également un contributeur important à la recherche en apprentissage profond.
    - LinkedIn : [Hugo Larochelle](https://www.linkedin.com/in/hugolarochelle/)
    - GitHub : [larochelle](https://github.com/larochelle)

## Experts en LLM (Large Language Models)

1. **Alec Radford** : Connu pour son travail sur les modèles GPT chez OpenAI, il est l'un des pionniers dans le développement des modèles de langage de grande taille.
   - LinkedIn : [Alec Radford](https://www.linkedin.com/in/alec-radford-28235810b/)
   - GitHub : [AlecRadford](https://github.com/AlecRadford)

2. **Tom B. Brown** : Un des principaux contributeurs au développement de GPT-3 chez OpenAI, il a joué un rôle clé dans l'entraînement des modèles de langage de grande taille.
   - LinkedIn : N/A
   - GitHub : [tommyb](https://github.com/tommyb)

3. **Sam Altman** : CEO d'OpenAI, il a supervisé le développement des grands modèles de langage, y compris GPT-3 et ChatGPT.
   - LinkedIn : [Sam Altman](https://www.linkedin.com/in/sama/)
   - GitHub : N/A

4. **Jack Clark** : Co-fondateur d'Anthropic, une entreprise spécialisée dans la recherche en IA, avec un focus sur le développement éthique des LLMs.
   - LinkedIn : [Jack Clark](https://www.linkedin.com/in/jack-clark/)
   - GitHub : N/A

5. **Noam Shazeer** : Co-inventeur du Transformer, l'architecture derrière les modèles de langage modernes tels que GPT-3. Il a également cofondé Character.AI, une entreprise de chatbots basés sur des LLMs.
   - LinkedIn : [Noam Shazeer](https://www.linkedin.com/in/noam-shazeer-52b920/)
   - GitHub : [noamshazeer](https://github.com/noamshazeer)

6. **Myle Ott** : Chercheur chez Meta AI (anciennement Facebook AI Research), il a contribué au développement de modèles de langage comme RoBERTa.
   - LinkedIn : [Myle Ott](https://www.linkedin.com/in/myle-ott-21427442/)
   - GitHub : [myloot](https://github.com/myloot)

7. **Colin Raffel** : Connu pour son travail sur T5 (Text-To-Text Transfer Transformer) chez Google Research, il a contribué à établir de nouvelles normes pour le traitement du langage naturel.
   - LinkedIn : [Colin Raffel](https://www.linkedin.com/in/colinraffel/)
   - GitHub : [colinraffel](https://github.com/colinraffel)

8. **Dario Amodei** : CEO et co-fondateur d'Anthropic, ancien chercheur principal chez OpenAI, il a contribué au développement de modèles de langage de grande taille.
   - LinkedIn : [Dario Amodei](https://www.linkedin.com/in/dario-amodei-0a93938b/)
   - GitHub : N/A

9. **Angela Fan** : Chercheuse chez Meta AI, elle a travaillé sur des modèles de langage comme XLM et a exploré les approches multilingues pour le traitement du langage naturel.
   - LinkedIn : [Angela Fan](https://www.linkedin.com/in/angela-fan-6223a8115/)
   - GitHub : [angelafan](https://github.com/angelafan)

10. **Ethan Perez** : Chercheur en IA, il a contribué à des modèles comme Reformer et aux efforts pour rendre les LLMs plus efficaces et interprétables.
    - LinkedIn : [Ethan Perez](https://www.linkedin.com/in/ethan-perez-764b88140/)
    - GitHub : [ethanjperez](https://github.com/ethanjperez)

11. **William Fedus** : Chercheur chez Google Brain, il a travaillé sur des modèles de langage comme GShard et exploré les techniques d'entraînement massivement parallèles.
    - LinkedIn : [William Fedus](https://www.linkedin.com/in/williamfedus/)
    - GitHub : [williamfedus](https://github.com/williamfedus)

12. **Jeremy Howard** : Co-fondateur de Fast.ai, il a été un pionnier dans la démocratisation de l'IA et de l'apprentissage profond. Il a également travaillé sur l'optimisation des grands modèles de langage pour les rendre plus accessibles.
    - LinkedIn : [Jeremy Howard](https://www.linkedin.com/in/jeremy-a-howard-2b799b/)
    - GitHub : [jeremyphoward](https://github.com/jeremyphoward)

13. **Lukas Biewald** : CEO et co-fondateur de Weights & Biases, une plateforme populaire utilisée pour le suivi et la gestion des expériences en deep learning. Son entreprise et ses travaux contribuent au développement et à l'optimisation des LLMs.
    - LinkedIn : [Lukas Biewald](https://www.linkedin.com/in/lukasbiewald/)
    - GitHub : [l2k](https://github.com/l2k)

14. **Michael Carbin** : Professeur au MIT et chercheur dans le domaine des systèmes de machine learning, il a exploré des méthodes pour optimiser et rendre plus fiables les grands modèles de langage.
    - LinkedIn : [Michael Carbin](https://www.linkedin.com/in/michael-carbin/)
    - GitHub : [mcarbin](https://github.com/mcarbin)

15. **Jacob Devlin** : Un des créateurs de BERT chez Google AI, il a contribué de manière significative à l'évolution des modèles de langage pré-entraînés.
    - LinkedIn : [Jacob Devlin](https://www.linkedin.com/in/jacob-devlin-0b37757/)
    - GitHub : N/A

16. **Nikita Kitaev** : Chercheur en intelligence artificielle chez Google Brain, il a travaillé sur des architectures de modèles de langage innovantes, comme le modèle Reformer, qui optimise la mémoire et la vitesse d'entraînement.
    - LinkedIn : [Nikita Kitaev](https://www.linkedin.com/in/nikitakitaev/)
    - GitHub : [nikitakit](https://github.com/nikitakit)

17. **Demis Hassabis** : CEO et co-fondateur de DeepMind, bien que plus focalisé sur l'intelligence artificielle en général, ses travaux ont influencé le développement des grands modèles de langage grâce à des innovations comme AlphaFold.
    - LinkedIn : [Demis Hassabis](https://www.linkedin.com/in/demishassabis/)
    - GitHub : N/A

## Experts en Prompt Engineering

1. **Riley Goodside** : Connu pour son expertise en prompt engineering, il partage régulièrement des astuces et des techniques pour améliorer l'interaction avec les modèles de langage. Il est souvent cité pour ses expérimentations créatives avec les prompts pour obtenir des résultats optimisés.
   - LinkedIn : [Riley Goodside](https://www.linkedin.com/in/rileygoodside/)
   - GitHub : [rileygoodside](https://github.com/rileygoodside)

2. **Gwern Branwen** : Chercheur indépendant qui a exploré en profondeur le potentiel des modèles de langage via l'optimisation des prompts. Il est reconnu pour ses analyses poussées et ses essais visant à maximiser la performance des LLMs.
   - LinkedIn : N/A
   - GitHub : [gwern](https://github.com/gwern)

3. **Margaret Mitchell** : Co-fondatrice de l'équipe d'éthique de l'IA chez Google, elle a aussi travaillé sur l'amélioration des interactions utilisateur-modèle, y compris l'optimisation des prompts pour des réponses plus fiables et éthiques.
   - LinkedIn : [Margaret Mitchell](https://www.linkedin.com/in/mmitchell-ai/)
   - GitHub : [mmitchell-ai](https://github.com/mmitchell-ai)

4. **Janelle Shane** : Scientifique et auteure, elle explore les comportements des modèles d'IA, souvent en utilisant des prompts créatifs pour révéler des biais ou des comportements inattendus, apportant ainsi une perspective unique au prompt engineering.
   - LinkedIn : [Janelle Shane](https://www.linkedin.com/in/janelle-shane-6664b645/)
   - GitHub : [JanelleCShane](https://github.com/JanelleCShane)

5. **Abhishek Thakur** : Expert en machine learning, il propose des tutoriels et des guides sur l'utilisation efficace des modèles de langage, y compris la conception de prompts pour maximiser la performance des LLMs.
   - LinkedIn : [Abhishek Thakur](https://www.linkedin.com/in/abhishek-thakur-823b535a/)
   - GitHub : [abhi1thakur](https://github.com/abhi1thakur)

6. **Reuven Cohen** : Expert dans l'intégration d'IA agentique, il est également actif dans l'optimisation des prompts pour améliorer la coordination et la collaboration entre agents IA pour des systèmes intelligents avancés.
   - LinkedIn : [Reuven Cohen](https://www.linkedin.com/in/reuvencohen/)
   - GitHub : [reuvencohen](https://github.com/reuvencohen)

7. **Simon Willison** : Développeur et expert en données, il a récemment exploré l'usage des prompts pour manipuler et extraire efficacement des informations de grands modèles de langage, en partageant ses trouvailles sur son blog et GitHub.
   - LinkedIn : [Simon Willison](https://www.linkedin.com/in/simonw/)
   - GitHub : [simonw](https://github.com/simonw)

8. **Boris Dayma** : Développeur de la populaire application "DALL-E Mini", il a également exploré et partagé des techniques de prompt engineering pour générer des images de qualité à partir de modèles de langage.
   - LinkedIn : [Boris Dayma](https://www.linkedin.com/in/borisdayma/)
   - GitHub : [borisdayma](https://github.com/borisdayma)

9. **Jeremy Howard** : En plus de son expertise en deep learning, il a également exploré l'optimisation des prompts pour maximiser l'efficacité des modèles de langage, notamment dans le cadre de Fast.ai.
   - LinkedIn : [Jeremy Howard](https://www.linkedin.com/in/jeremy-a-howard-2b799b/)
   - GitHub : [jeremyphoward](https://github.com/jeremyphoward)

10. **Christina Kim** : Chercheuse en IA chez Hugging Face, elle a exploré l'optimisation des prompts pour améliorer l'équité, l'explicabilité, et la performance des modèles de langage.
    - LinkedIn : [Christina Kim](https://www.linkedin.com/in/christina-kim-ai/)
    - GitHub : [cristinaykim](https://github.com/cristinaykim)

11. **Minimaxir (Max Woolf)** : Un des premiers à expérimenter avec les prompts GPT-2 et GPT-3 pour générer du contenu créatif, il a partagé ses découvertes sur la meilleure façon d'interagir avec ces modèles.
    - LinkedIn : [Max Woolf](https://www.linkedin.com/in/minimaxir/)
    - GitHub : [minimaxir](https://github.com/minimaxir)

12. **Raphaël Millière** : Chercheur en IA et philosophie, il s'est concentré sur la manière dont les modèles de langage interagissent avec les prompts et les implications éthiques de ces interactions.
    - LinkedIn : [Raphaël Millière](https://www.linkedin.com/in/raphael-milliere/)
    - GitHub : N/A

13. **Julian Togelius** : Professeur à NYU, il a exploré l'utilisation des prompts dans les jeux vidéo pour créer des IA plus adaptatives et engageantes.
    - LinkedIn : [Julian Togelius](https://www.linkedin.com/in/juliantogelius/)
    - GitHub : [togelius](https://github.com/togelius)

14. **Jason Wei** : Chercheur en IA chez Google, il a travaillé sur la façon dont les prompts peuvent être structurés pour améliorer la performance des LLMs sur une variété de tâches, notamment en ajustant le format des instructions.
    - LinkedIn : [Jason Wei](https://www.linkedin.com/in/jason-wei-719b57121/)
    - GitHub : [jasonwei20](https://github.com/jasonwei20)

